# ğŸ“˜ KnowledgeAI â€“ Document Q&A System

**Knowledge AI** is an end-to-end **Retrieval-Augmented Generation (RAG)** system that allows users to *upload documents from the Frontend* and then *query them through natural language*. Powered by **LangChain, LangGraph, Gemini, Pinecone**

---
## âœ¨ Features

- ğŸ’¡ **Document Upload**:
Upload files (.pdf, .txt, etc.) directly from the frontend.


- âš™ **Automatic Chunking**:
Splits large documents into manageable chunks for efficient retrieval.


- ğŸ“ **Smart Embeddings**:
Uses Google Generative AI Embeddings (Gemini) to represent document content.


- ğŸ§¾ **Semantic Search**:
Stores embeddings in Pinecone for fast and relevant similarity search.


- ğŸ”Š **Question Answering**:
Ask questions about uploaded documents and get precise, context-aware answers.


- **Frontend**  
    - âš› React  
    - ğŸŸ¦ TypeScript  
    - ğŸ¨ TailwindCSS  

- **Backend**  
    - ğŸš€ FastAPI  
    - ğŸ”— LangChain  
    - ğŸ§© LangGraph  
    - ğŸ“¦ Pinecone  
    - ğŸ¤– Gemini LLM  
   
---

## ğŸ§  Tech Stack
| Layer | Tools |
|-------|-------|
| LLM | Gemini, LangChain, LangGraph |
| Frontend | React, Typescript, HTML5/CSS3, TailwindCSS |
| Backend | Python, FastAPI, Uvicorn|
| Vector Database | Pinecone |
| Workflow Graph | LangGraph |

---

## ğŸ—‚ Project Structure
 ```
 KnowledgeAI/
â”‚
â”œâ”€â”€ Backend/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ api.py # FastAPI routes for /upload and /ask
â”‚ â”‚ â”œâ”€â”€ nodes/ # Node functions: load_documents, chunking, embeddings, query, answer
â”‚ â”‚ â”œâ”€â”€ workflows/ # LangGraph ingestion graph
â”‚ â”‚ â”œâ”€â”€ utils.py # Helpers: split documents, enhance query
â”‚ â”‚ â””â”€â”€ embeddings.py # Vector store creation with Pinecone
â”‚ â”œâ”€â”€ .env # API keys for Gemini & Pinecone
â”‚ â””â”€â”€ requirements.txt # Python dependencies
â”‚
â”œâ”€â”€ Frontend/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ api.ts # Axios API calls
â”‚ â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”‚ â”œâ”€â”€ Upload.tsx # File upload component
â”‚ â”‚ â”‚ â””â”€â”€ Chat.tsx # Chat interface component
â”‚ â”‚ â”œâ”€â”€ App.tsx # Main app entry
â”‚ â”‚ â””â”€â”€ index.tsx # React root file
â”‚ â”œâ”€â”€ package.json # Node dependencies
â”‚ â””â”€â”€ tailwind.config.js # TailwindCSS configuration
â”‚
â”œâ”€â”€ README.md
 ```


---

## ğŸš€ Getting Started

## Clone the repo
```
git clone https://github.com/yourusername/your-project-name
cd KNOWLEDGEAI
```
 ## To set up Backend
 1. Navigate to Backend Folder
    ```
    cd Backend
    ```

 2. Activate Virtual Environment or create if needed
    ```
    python -m venv .venv
    .venv\Scripts\activate   # Windows
    source .venv/bin/activate   # Mac/Linux
    ```
  
  3. Install Dependencies
     ```
     pip install -r requiremnts.txt
     ```
  
  4. Add .env file
     ```
      GEMINI_API_KEY=your_api_key
      PINECONE_API_KEY=your_api_key
     ```
  
  5. Run the Fast API Server
     ```
     uvicorn src.api:app --reload
     ```


 ## To set up Frontend
 1. Navigate to Frontend Folder
    ```
    cd Frontend
    ```

 2. Install Dependencies
     ```
     npm install
     ```
  
  3.  Run the DEV Server
      ``` 
       npm dev run
      ```    

---
## ğŸ—£ How It Works

### ğŸ–¥ Frontend  
- Users can **upload documents** (`.pdf`, `.txt`) via a simple UI.  
- After processing, users can **ask natural language questions** about the uploaded document.  
- The UI communicates with the backend using **Axios API calls**.  

### âš¡ Backend  

**File Upload API (`/upload`)**  
- Accepts the file from the frontend.  
- Reads the contents and **splits them into smaller chunks** for better retrieval.  
- Generates **vector embeddings** using **Google Generative AI embeddings (Gemini)**.  
- Stores embeddings in **Pinecone** for semantic search.  

**Query API (`/ask`)**  
- Enhances the user query with **Gemini LLM** for better retrieval quality.  
- Searches **Pinecone** for the most relevant chunks.  
- Uses the **LLM** to generate a final, context-aware answer.  

### ğŸ”— Workflow (Ingestion Pipeline with LangGraph)  
1. Upload File â†’ Load Documents
2. Chunk Documents â†’ Create Embeddings  
3. Store in Pinecone â†’ Summarize

ğŸ§ª **Example Prompts**
- â€œI have uploaded a PDF about life, explain about lifeâ€
- â€œExplain about necessities for a happy lifeâ€


---  

### ğŸ‘¨â€ğŸ’» Author: Sameeksha Vaishnavi
ğŸ“„ MIT License â€“ Feel free to use, modify and distribute!
